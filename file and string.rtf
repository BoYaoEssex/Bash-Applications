{\rtf1\ansi\ansicpg936\cocoartf2577
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs29\fsmilli14667 \cf2 \expnd0\expndtw0\kerning0
# Read from the file file.txt and output the tenth line to stdout.\
lineNumber=0\
while [ $lineNumber -le 10 ]; do\
\'a0\'a0\'a0 read line\
\'a0\'a0\'a0 if [ -z "$line" ]; then\
\'a0\'a0\'a0\'a0\'a0\'a0\'a0 exit 0\
\'a0\'a0\'a0 fi\
\'a0\'a0\'a0 let 'lineNumber = lineNumber + 1'\
\'a0\'a0\'a0 if [ $lineNumber -eq 10 ]; then\
\'a0\'a0\'a0\'a0\'a0\'a0\'a0 echo $line\
\'a0\'a0\'a0\'a0\'a0\'a0\'a0 exit 0\
\'a0\'a0\'a0 fi\
done < file.txt\
\'a0\
<<COMMENT\
Input (in file.txt):\
Line 1\
Line 2\
Line 3\
Line 4\
Line 5\
Line 6\
Line 7\
Line 8\
Line 9\
Line 10\
\'a0\
Output:\
Line 10\
\'a0\
COMMENT\
\
\
\
\
\
# Read from the file file.txt and output all valid phone numbers to stdout.\
grep -e '\\(^[0-9]\\\{3\\\}-[0-9]\\\{3\\\}-[0-9]\\\{4\\\}$\\)' -e '\\(^([0-9]\\\{3\\\})[ ]\\\{1\\\}[0-9]\\\{3\\\}-\\([0-9]\\\{4\\\}\\)$\\)'\'a0 file.txt\
\'a0\
<<COMMENT\
valid phone number must appear in one of the following two formats: \
(xxx) xxx-xxxx or xxx-xxx-xxxx. (x means a digit)\
\'a0\
Input (in file.txt):\
987-123-4567\
123 456 7890\
(123) 456-7890\
\'a0\
Output (valid numbers):\
987-123-4567\
(123) 456-7890\
\'a0\
Code explaination:\
grep: find out sepecific strings from input source\
-e: regexp that target strings matches\
^ : the beginning of a line\
$ : the end of a line\
\{n\} : match exactly n times of the previous regex\
(...) : group regex together\
\'a0\
COMMENT\
\
\
\
\
# Read from the file words.txt and output the word frequency list to stdout.\
cat words.txt | tr -s ' ' '\\n' | sort | uniq --count | sort -r | awk '\{print $2 " " $1\}'\
\'a0\
<<COMMENT\
Input (in words.txt): \
the day is sunny the the\
the sunny is is\
\'a0\
Output(words and their frequencies): \
the 4\
is 3\
sunny 2\
day 1\
\'a0\
Code explaination:\
cat : to concatenate, create single or multiple files\
tr\'a0 : for truncating the input. cat words.txt | tr -s ' ' '\\n' will\
\'a0\'a0\'a0\'a0\'a0 truncatie each whitespace(' ') and replace it with newline('\\n')\
sort: This sort the input in ascending order so that uniq can find \
\'a0\'a0\'a0\'a0\'a0 duplicatewords adjacently. \
\'a0\'a0\'a0\'a0\'a0 cat words.txt | tr -s ' ' '\\n' | sort\'a0\'a0\'a0 \
\'a0\'a0\'a0\'a0\'a0\'a0\'a0 day\
\'a0\'a0\'a0\'a0\'a0\'a0\'a0 is\
\'a0\'a0\'a0\'a0\'a0\'a0\'a0 is\
\'a0\'a0\'a0\'a0\'a0\'a0\'a0 is\
\'a0\'a0\'a0\'a0\'a0\'a0\'a0 sunny\
\'a0\'a0\'a0\'a0\'a0\'a0\'a0 sunny\
\'a0\'a0\'a0\'a0\'a0\'a0\'a0 the\
\'a0\'a0\'a0\'a0\'a0\'a0\'a0 the\
\'a0\'a0\'a0\'a0\'a0\'a0\'a0 the\
\'a0\'a0\'a0\'a0\'a0\'a0\'a0 the\
uniq --count: This command provides word frequency as "count word" format.\
Filter adjacent matching lines from INPUT (or standard input),\
writing to OUTPUT.\'a0 ~ cat words.txt | tr -s ' ' '\\n' | sort | uniq --count\
\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0 1 day\
\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0 3 is\
\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0 2 sunny\
\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0 4 the\
sort -r: sorts the input in descending order.\
\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0 4 the\
\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0 3 is\
\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0 2 sunny\
\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0\'a0 1 day\
awk '\{print $2 " " $1\}\
awk formats the input given for each line. In our case, we want the \
second column ($2) appears first and the first column ($1) appears second \
separated by whitespace(" ")\
\'a0\
COMMENT\
}